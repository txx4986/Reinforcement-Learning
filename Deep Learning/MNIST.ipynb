{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP: Image Classification on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 11:01:24.282630: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Load or Download MNIST > data/mnist\n",
      "[TL] data/mnist/train-images-idx3-ubyte.gz\n",
      "[TL] data/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# loading the MNSIT dataset by TensorLayer\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n",
    "# each image in MNIST is originally sized 28x28, i.e. has 784 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Input  _inputlayer_1: [None, 784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Dropout dropout_1: keep: 0.800000 \n",
      "[TL] Dense  dense_1: 800 relu\n",
      "[TL] Dropout dropout_2: keep: 0.500000 \n",
      "[TL] Dense  dense_2: 800 relu\n",
      "[TL] Dropout dropout_3: keep: 0.500000 \n",
      "[TL] Dense  dense_3: 10 No Activation\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "ni = tl.layers.Input([None, 784])  # the input is aligned with the shape of data\n",
    "# the layers of the MLP is connected one by one\n",
    "nn = tl.layers.Dropout(keep=0.8)(ni)\n",
    "nn = tl.layers.Dense(n_units=800, act=tf.nn.relu)(nn)\n",
    "nn = tl.layers.Dropout(keep=0.5)(nn)\n",
    "nn = tl.layers.Dense(n_units=800, act=tf.nn.relu)(nn)\n",
    "nn = tl.layers.Dropout(keep=0.5)(nn)\n",
    "nn = tl.layers.Dense(n_units=10, act=None)(nn)\n",
    "# create the model with specified inputs and outputs\n",
    "network = tl.models.Model(inputs=ni, outputs=nn, name=\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a metric to evaluate the accuracy of the model\n",
    "# different from the loss function, the metric is NOT ised to backpropagate or update the model\n",
    "def acc(_logits, y_batch):\n",
    "    # return np.mean(np.equal(np.argmax(_logits, 1), y_batch))\n",
    "    return tf.reduce_mean(\n",
    "        tf.cast(\n",
    "            tf.equal(\n",
    "                tf.argmax(_logits, 1),\n",
    "                tf.convert_to_tensor(y_batch, tf.int64)),\n",
    "            tf.float32),\n",
    "        name='accuracy'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Finished! use `tensorboard --logdir=None/` to start tensorboard\n",
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 20 took 5.226250s\n",
      "[TL]    train loss: 0.413133\n",
      "[TL]    train acc: 0.884716\n",
      "[TL] Epoch 5 of 20 took 4.255809s\n",
      "[TL]    train loss: 0.191547\n",
      "[TL]    train acc: 0.943149\n",
      "[TL] Epoch 10 of 20 took 3.595602s\n",
      "[TL]    train loss: 0.122305\n",
      "[TL]    train acc: 0.962981\n",
      "[TL] Epoch 15 of 20 took 3.611428s\n",
      "[TL]    train loss: 0.088144\n",
      "[TL]    train acc: 0.973498\n",
      "[TL] Epoch 20 of 20 took 4.129800s\n",
      "[TL]    train loss: 0.067379\n",
      "[TL]    train acc: 0.979728\n",
      "[TL] Total training time: 85.557495s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "tl.utils.fit(\n",
    "    network,  # the model\n",
    "    train_op=tf.optimizers.Adam(learning_rate=0.0001),  # the optimizer\n",
    "    cost=tl.cost.cross_entropy,  # the loss function\n",
    "    X_train=X_train, y_train=y_train,  # the training set\n",
    "    acc=acc,  # the metrics to evaluate the accuracy of a model\n",
    "    batch_size=256,  # the size of mini-batch\n",
    "    n_epoch=20,  # number of epoch to train\n",
    "    X_val=X_val, y_val=y_val, eval_train=True  # validation set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Start testing the network ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.973>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "tl.utils.test(\n",
    "    network,  # the model just trained\n",
    "    acc=acc,  # the metrics to evaluate the accuracy of a model\n",
    "    X_test=X_test, y_test=y_test,  # testing set\n",
    "    batch_size=None,  # the size of mini-batch. If None, the whole testing set is fed into the network together, so only set it None when the testing set is small\n",
    "    cost=tl.cost.cross_entropy  # the loss function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] confusion matrix: \n",
      "[[ 970    0    1    1    0    1    4    1    2    0]\n",
      " [   0 1126    2    1    0    1    2    0    3    0]\n",
      " [   5    0 1006    5    2    0    2    7    5    0]\n",
      " [   0    0    6  985    0    3    0    8    6    2]\n",
      " [   1    0    4    0  961    0    3    1    2   10]\n",
      " [   4    0    0   17    1  854    8    1    4    3]\n",
      " [   6    3    0    1    4    4  936    0    4    0]\n",
      " [   1    7   11    3    1    0    0  991    0   14]\n",
      " [   4    1    3    8    4    3    4    4  940    3]\n",
      " [   5    6    1   10   13    1    0    5    7  961]]\n",
      "[TL] f1-score        : [0.98178138 0.98858648 0.97386254 0.96521313 0.97662602 0.97100625\n",
      " 0.97652582 0.96871945 0.96558808 0.96003996]\n",
      "[TL] f1-score(macro) : 0.972795\n",
      "[TL] accuracy-score  : 0.973000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 970,    0,    1,    1,    0,    1,    4,    1,    2,    0],\n",
       "        [   0, 1126,    2,    1,    0,    1,    2,    0,    3,    0],\n",
       "        [   5,    0, 1006,    5,    2,    0,    2,    7,    5,    0],\n",
       "        [   0,    0,    6,  985,    0,    3,    0,    8,    6,    2],\n",
       "        [   1,    0,    4,    0,  961,    0,    3,    1,    2,   10],\n",
       "        [   4,    0,    0,   17,    1,  854,    8,    1,    4,    3],\n",
       "        [   6,    3,    0,    1,    4,    4,  936,    0,    4,    0],\n",
       "        [   1,    7,   11,    3,    1,    0,    0,  991,    0,   14],\n",
       "        [   4,    1,    3,    8,    4,    3,    4,    4,  940,    3],\n",
       "        [   5,    6,    1,   10,   13,    1,    0,    5,    7,  961]]),\n",
       " array([0.98178138, 0.98858648, 0.97386254, 0.96521313, 0.97662602,\n",
       "        0.97100625, 0.97652582, 0.96871945, 0.96558808, 0.96003996]),\n",
       " 0.973,\n",
       " 0.972794911127844)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# evaluation\n",
    "_logits = tl.utils.predict(network, X_test)\n",
    "y_pred = np.argmax(_logits, 1)\n",
    "tl.utils.evaluation(y_test, y_pred, n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] [*] Saving TL weights into model.MNIST\n",
      "[TL] [*] Saved\n"
     ]
    }
   ],
   "source": [
    "# save network weights to a file\n",
    "network.save_weights('model.MNIST')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RI_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
